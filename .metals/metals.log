2024.03.04 21:12:15 INFO  Started: Metals version 1.2.2 in folders 'C:\Users\jland\Documents\CS474_Paper_Project' for client Visual Studio Code 1.87.0.
21:12:16.334 [pool-1-thread-4] INFO org.flywaydb.core.internal.license.VersionPrinter -- Flyway Community Edition 9.22.3 by Redgate
21:12:16.335 [pool-1-thread-4] INFO org.flywaydb.core.internal.license.VersionPrinter -- See release notes here: https://rd.gt/416ObMi
21:12:16.335 [pool-1-thread-4] INFO org.flywaydb.core.internal.license.VersionPrinter -- 
21:12:16.336 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Scanning for classpath resources at 'classpath:db/callback' ...
21:12:16.336 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Determining location urls for classpath:db/callback using ClassLoader jdk.internal.loader.ClassLoaders$AppClassLoader@70dea4e ...
21:12:16.337 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Unable to resolve location classpath:db/callback.
21:12:16.337 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Scanning for classpath resources at 'classpath:db/migration' ...
21:12:16.337 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Determining location urls for classpath:db/migration using ClassLoader jdk.internal.loader.ClassLoaders$AppClassLoader@70dea4e ...
21:12:16.337 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Scanning URL: jar:file:/C:/Users/jland/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/scalameta/metals_2.13/1.2.2/metals_2.13-1.2.2.jar!/db/migration
21:12:16.341 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/
21:12:16.341 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/V1__Create_tables.sql
21:12:16.341 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/V2__Server_discovery.sql
21:12:16.341 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/V3__Jar_symbols.sql
21:12:16.341 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/V4__Fingerprints.sql
21:12:16.341 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Scanning for classes at classpath:db/migration
21:12:16.343 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
21:12:16.343 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.resource.ResourceNameValidator -- Validating V1__Create_tables.sql
21:12:16.343 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.resource.ResourceNameValidator -- Validating V3__Jar_symbols.sql
21:12:16.343 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.resource.ResourceNameValidator -- Validating V2__Server_discovery.sql
21:12:16.343 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.resource.ResourceNameValidator -- Validating V4__Fingerprints.sql
21:12:16.403 [pool-1-thread-4] INFO org.flywaydb.core.FlywayExecutor -- Database: jdbc:h2:file:C:\Users\jland\Documents\CS474_Paper_Project\.metals\metals (H2 2.2)
21:12:16.403 [pool-1-thread-4] DEBUG org.flywaydb.core.FlywayExecutor -- Driver: H2 JDBC Driver 2.2.224 (2023-09-17)
21:12:16.403 [pool-1-thread-4] DEBUG org.flywaydb.core.FlywayExecutor -- DDL Transactions Supported: false
21:12:16.404 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.schemahistory.SchemaHistoryFactory -- Schemas: 
21:12:16.404 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.schemahistory.SchemaHistoryFactory -- Default schema: null
21:12:16.406 [pool-1-thread-4] WARN org.flywaydb.core.internal.database.base.Database -- Flyway upgrade recommended: H2 2.2.224 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
21:12:16.407 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.callback.SqlScriptCallbackFactory -- Scanning for SQL callbacks ...
21:12:16.407 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
21:12:16.412 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.command.DbValidate -- Validating migrations ...
21:12:16.413 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
21:12:16.418 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V1__Create_tables.sql (filename: V1__Create_tables.sql)
21:12:16.418 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
21:12:16.418 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V3__Jar_symbols.sql (filename: V3__Jar_symbols.sql)
21:12:16.418 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V2__Server_discovery.sql (filename: V2__Server_discovery.sql)
21:12:16.418 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V4__Fingerprints.sql (filename: V4__Fingerprints.sql)
21:12:16.418 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V1__Create_tables.sql (filename: V1__Create_tables.sql)
21:12:16.418 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
21:12:16.418 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V3__Jar_symbols.sql (filename: V3__Jar_symbols.sql)
21:12:16.418 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V2__Server_discovery.sql (filename: V2__Server_discovery.sql)
21:12:16.418 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V4__Fingerprints.sql (filename: V4__Fingerprints.sql)
21:12:16.419 [pool-1-thread-4] INFO org.flywaydb.core.internal.schemahistory.JdbcTableSchemaHistory -- Schema history table "PUBLIC"."flyway_schema_history" does not exist yet
21:12:16.420 [pool-1-thread-4] INFO org.flywaydb.core.internal.command.DbValidate -- Successfully validated 4 migrations (execution time 00:00.008s)
21:12:16.422 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.command.DbSchemas -- Skipping creation of existing schema: "PUBLIC"
21:12:16.424 [pool-1-thread-4] INFO org.flywaydb.core.internal.schemahistory.JdbcTableSchemaHistory -- Creating Schema History table "PUBLIC"."flyway_schema_history" ...
21:12:16.425 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.parser.Parser -- Parsing  ...
21:12:16.431 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.sqlscript.ParserSqlScript -- Found statement at line 1: CREATE TABLE IF NOT EXISTS "PUBLIC"."flyway_schema_history" (
    "installed_rank" INT NOT NULL,
    "version" VARCHAR(50),
    "description" VARCHAR(200) NOT NULL,
    "type" VARCHAR(20) NOT NULL,
    "script" VARCHAR(1000) NOT NULL,
    "checksum" INT,
    "installed_by" VARCHAR(100) NOT NULL,
    "installed_on" TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
    "execution_time" INT NOT NULL,
    "success" BOOLEAN NOT NULL,
    CONSTRAINT "flyway_schema_history_pk" PRIMARY KEY ("installed_rank")
) AS SELECT -1, NULL, '<< Flyway Schema History table created >>', 'TABLE', '', NULL, 'SA', CURRENT_TIMESTAMP, 0, TRUE
21:12:16.431 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.sqlscript.ParserSqlScript -- Found statement at line 14: CREATE INDEX "PUBLIC"."flyway_schema_history_s_idx" ON "PUBLIC"."flyway_schema_history" ("success")
21:12:16.432 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.sqlscript.DefaultSqlScriptExecutor -- Executing SQL: CREATE TABLE IF NOT EXISTS "PUBLIC"."flyway_schema_history" (
    "installed_rank" INT NOT NULL,
    "version" VARCHAR(50),
    "description" VARCHAR(200) NOT NULL,
    "type" VARCHAR(20) NOT NULL,
    "script" VARCHAR(1000) NOT NULL,
    "checksum" INT,
    "installed_by" VARCHAR(100) NOT NULL,
    "installed_on" TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
    "execution_time" INT NOT NULL,
    "success" BOOLEAN NOT NULL,
    CONSTRAINT "flyway_schema_history_pk" PRIMARY KEY ("installed_rank")
) AS SELECT -1, NULL, '<< Flyway Schema History table created >>', 'TABLE', '', NULL, 'SA', CURRENT_TIMESTAMP, 0, TRUE
21:12:16.435 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.sqlscript.DefaultSqlScriptExecutor -- 0 rows affected
21:12:16.435 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.sqlscript.DefaultSqlScriptExecutor -- Executing SQL: CREATE INDEX "PUBLIC"."flyway_schema_history_s_idx" ON "PUBLIC"."flyway_schema_history" ("success")
21:12:16.437 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.sqlscript.DefaultSqlScriptExecutor -- 0 rows affected
21:12:16.437 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.schemahistory.JdbcTableSchemaHistory -- Created Schema History table "PUBLIC"."flyway_schema_history"
21:12:16.440 [pool-1-thread-4] INFO org.flywaydb.core.internal.command.DbMigrate -- Current version of schema "PUBLIC": << Empty Schema >>
21:12:16.440 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.parser.Parser -- Parsing V1__Create_tables.sql ...
21:12:16.441 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.sqlscript.ParserSqlScript -- Found statement at line 4: -- The relationship between library dependency sources under .metals/readonly/**
-- and build targets they belong to. Required to know what classpath to use
-- for compiling dependency sources.
create table dependency_source(
  text_document_uri varchar primary key,
  build_target_uri varchar not null
)
21:12:16.442 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.sqlscript.ParserSqlScript -- Found statement at line 12: -- The relationship between library dependency sources under .metals/readonly/**
-- and worksheets they belong to. Required to know what classpath to use
-- for compiling dependency sources.
create table worksheet_dependency_source(
  text_document_uri varchar primary key,
  worksheet_uri varchar not null
)
21:12:16.442 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.sqlscript.ParserSqlScript -- Found statement at line 19: -- The relationship between what library dependency sources under .metals/readonly/**
-- map to which build targets.
create table sbt_digest(
  md5 varchar,
  status tinyint not null,
  when_recorded timestamp
)
21:12:16.443 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.sqlscript.ParserSqlScript -- Found statement at line 27: -- Which window/showMessage and window/showMessageRequest dialogues have been dismissed
-- by the user via "Don't show again" or closed by clicking on "x".
create table dismissed_notification(
  id int,
  when_dismissed timestamp,
  when_expires timestamp
)
21:12:16.443 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.sqlscript.ParserSqlScript -- Found statement at line 34: -- The choice of build tool when multiple build tool files are found in a workspace
create table chosen_build_tool(
  build_tool varchar primary key
)
21:12:16.444 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.command.DbMigrate -- Starting migration of schema "PUBLIC" to version "1 - Create tables" ...
21:12:16.445 [pool-1-thread-4] INFO org.flywaydb.core.internal.command.DbMigrate -- Migrating schema "PUBLIC" to version "1 - Create tables"
21:12:16.445 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.sqlscript.DefaultSqlScriptExecutor -- Executing SQL: -- The relationship between library dependency sources under .metals/readonly/**
-- and build targets they belong to. Required to know what classpath to use
-- for compiling dependency sources.
create table dependency_source(
  text_document_uri varchar primary key,
  build_target_uri varchar not null
)
21:12:16.445 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.sqlscript.DefaultSqlScriptExecutor -- 0 rows affected
21:12:16.445 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.sqlscript.DefaultSqlScriptExecutor -- Executing SQL: -- The relationship between library dependency sources under .metals/readonly/**
-- and worksheets they belong to. Required to know what classpath to use
-- for compiling dependency sources.
create table worksheet_dependency_source(
  text_document_uri varchar primary key,
  worksheet_uri varchar not null
)
21:12:16.446 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.sqlscript.DefaultSqlScriptExecutor -- 0 rows affected
21:12:16.447 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.sqlscript.DefaultSqlScriptExecutor -- Executing SQL: -- The relationship between what library dependency sources under .metals/readonly/**
-- map to which build targets.
create table sbt_digest(
  md5 varchar,
  status tinyint not null,
  when_recorded timestamp
)
21:12:16.448 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.sqlscript.DefaultSqlScriptExecutor -- 0 rows affected
21:12:16.448 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.sqlscript.DefaultSqlScriptExecutor -- Executing SQL: -- Which window/showMessage and window/showMessageRequest dialogues have been dismissed
-- by the user via "Don't show again" or closed by clicking on "x".
create table dismissed_notification(
  id int,
  when_dismissed timestamp,
  when_expires timestamp
)
21:12:16.448 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.sqlscript.DefaultSqlScriptExecutor -- 0 rows affected
21:12:16.448 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.sqlscript.DefaultSqlScriptExecutor -- Executing SQL: -- The choice of build tool when multiple build tool files are found in a workspace
create table chosen_build_tool(
  build_tool varchar primary key
)
21:12:16.449 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.sqlscript.DefaultSqlScriptExecutor -- 0 rows affected
21:12:16.449 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.command.DbMigrate -- Successfully completed migration of schema "PUBLIC" to version "1 - Create tables"
21:12:16.451 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.schemahistory.JdbcTableSchemaHistory -- Schema History table "PUBLIC"."flyway_schema_history" successfully updated to reflect changes
21:12:16.453 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.parser.Parser -- Parsing V2__Server_discovery.sql ...
21:12:16.454 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.sqlscript.ParserSqlScript -- Found statement at line 4: -- For each unique combination of installed build servers we select one server.
-- The md5 checksum is computed from the names of the installed build servers, and
-- the selected server is the server which the user chose for this workspace.
create table chosen_build_server(
  md5 varchar primary key,
  selected_server varchar,
  when_recorded timestamp
)
21:12:16.454 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.command.DbMigrate -- Starting migration of schema "PUBLIC" to version "2 - Server discovery" ...
21:12:16.455 [pool-1-thread-4] INFO org.flywaydb.core.internal.command.DbMigrate -- Migrating schema "PUBLIC" to version "2 - Server discovery"
21:12:16.455 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.sqlscript.DefaultSqlScriptExecutor -- Executing SQL: -- For each unique combination of installed build servers we select one server.
-- The md5 checksum is computed from the names of the installed build servers, and
-- the selected server is the server which the user chose for this workspace.
create table chosen_build_server(
  md5 varchar primary key,
  selected_server varchar,
  when_recorded timestamp
)
21:12:16.455 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.sqlscript.DefaultSqlScriptExecutor -- 0 rows affected
21:12:16.455 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.command.DbMigrate -- Successfully completed migration of schema "PUBLIC" to version "2 - Server discovery"
21:12:16.456 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.schemahistory.JdbcTableSchemaHistory -- Schema History table "PUBLIC"."flyway_schema_history" successfully updated to reflect changes
21:12:16.457 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.parser.Parser -- Parsing V3__Jar_symbols.sql ...
21:12:16.458 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.sqlscript.ParserSqlScript -- Found statement at line 2: -- Indexed jars, the MD5 digest of path, modified time and size as key
create table indexed_jar(
  id int auto_increment unique,
  md5 varchar primary key
)
21:12:16.458 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.sqlscript.ParserSqlScript -- Found statement at line 7: -- Top Level Symbols per jar, allow for multiple jars with same symbols and paths
create table toplevel_symbol(
  symbol varchar not null,
  path varchar not null,
  jar int,
  foreign key (jar) references indexed_jar (id) on delete cascade,
  primary key (jar, path, symbol)
)
21:12:16.458 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.sqlscript.ParserSqlScript -- Found statement at line 15: -- Create index to speedup lookup of jar symbols
create index toplevel_symbol_jar on toplevel_symbol(jar)
21:12:16.458 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.command.DbMigrate -- Starting migration of schema "PUBLIC" to version "3 - Jar symbols" ...
21:12:16.459 [pool-1-thread-4] INFO org.flywaydb.core.internal.command.DbMigrate -- Migrating schema "PUBLIC" to version "3 - Jar symbols"
21:12:16.459 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.sqlscript.DefaultSqlScriptExecutor -- Executing SQL: -- Indexed jars, the MD5 digest of path, modified time and size as key
create table indexed_jar(
  id int auto_increment unique,
  md5 varchar primary key
)
21:12:16.462 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.sqlscript.DefaultSqlScriptExecutor -- 0 rows affected
21:12:16.462 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.sqlscript.DefaultSqlScriptExecutor -- Executing SQL: -- Top Level Symbols per jar, allow for multiple jars with same symbols and paths
create table toplevel_symbol(
  symbol varchar not null,
  path varchar not null,
  jar int,
  foreign key (jar) references indexed_jar (id) on delete cascade,
  primary key (jar, path, symbol)
)
21:12:16.464 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.sqlscript.DefaultSqlScriptExecutor -- 0 rows affected
21:12:16.464 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.sqlscript.DefaultSqlScriptExecutor -- Executing SQL: -- Create index to speedup lookup of jar symbols
create index toplevel_symbol_jar on toplevel_symbol(jar)
21:12:16.465 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.sqlscript.DefaultSqlScriptExecutor -- 0 rows affected
21:12:16.465 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.command.DbMigrate -- Successfully completed migration of schema "PUBLIC" to version "3 - Jar symbols"
21:12:16.466 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.schemahistory.JdbcTableSchemaHistory -- Schema History table "PUBLIC"."flyway_schema_history" successfully updated to reflect changes
21:12:16.467 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.parser.Parser -- Parsing V4__Fingerprints.sql ...
21:12:16.468 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.sqlscript.ParserSqlScript -- Found statement at line 2: -- Fingerprints saved between invocations
create table fingerprints(
  path varchar not null,
  text varchar not null,
  md5 varchar not null,
  id int auto_increment unique
)
21:12:16.468 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.command.DbMigrate -- Starting migration of schema "PUBLIC" to version "4 - Fingerprints" ...
21:12:16.469 [pool-1-thread-4] INFO org.flywaydb.core.internal.command.DbMigrate -- Migrating schema "PUBLIC" to version "4 - Fingerprints"
21:12:16.469 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.sqlscript.DefaultSqlScriptExecutor -- Executing SQL: -- Fingerprints saved between invocations
create table fingerprints(
  path varchar not null,
  text varchar not null,
  md5 varchar not null,
  id int auto_increment unique
)
21:12:16.469 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.sqlscript.DefaultSqlScriptExecutor -- 0 rows affected
21:12:16.470 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.command.DbMigrate -- Successfully completed migration of schema "PUBLIC" to version "4 - Fingerprints"
21:12:16.470 [pool-1-thread-4] DEBUG org.flywaydb.core.internal.schemahistory.JdbcTableSchemaHistory -- Schema History table "PUBLIC"."flyway_schema_history" successfully updated to reflect changes
21:12:16.473 [pool-1-thread-4] INFO org.flywaydb.core.internal.command.DbMigrate -- Successfully applied 4 migrations to schema "PUBLIC", now at version v4 (execution time 00:00.012s)
21:12:16.479 [pool-1-thread-4] DEBUG org.flywaydb.core.FlywayExecutor -- Memory usage: 75 of 120M
2024.03.04 21:12:16 WARN  no build tool detected in workspace 'C:\Users\jland\Documents\CS474_Paper_Project'. The most common cause for this problem is that the editor was opened in the wrong working directory, for example if you use sbt then the workspace directory should contain build.sbt. 
2024.03.04 21:12:16 WARN  Build server is not auto-connectable.
2024.03.04 21:12:43 INFO  Shutting down server
2024.03.04 21:12:43 INFO  shutting down Metals
2024.03.04 21:12:43 INFO  Exiting server
2024.03.04 21:13:06 INFO  Started: Metals version 1.2.2 in folders 'C:\Users\jland\Documents\CS474_Paper_Project' for client Visual Studio Code 1.87.0.
21:13:07.118 [pool-1-thread-2] INFO org.flywaydb.core.internal.license.VersionPrinter -- Flyway Community Edition 9.22.3 by Redgate
21:13:07.119 [pool-1-thread-2] INFO org.flywaydb.core.internal.license.VersionPrinter -- See release notes here: https://rd.gt/416ObMi
21:13:07.119 [pool-1-thread-2] INFO org.flywaydb.core.internal.license.VersionPrinter -- 
21:13:07.121 [pool-1-thread-2] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Scanning for classpath resources at 'classpath:db/callback' ...
21:13:07.121 [pool-1-thread-2] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Determining location urls for classpath:db/callback using ClassLoader jdk.internal.loader.ClassLoaders$AppClassLoader@70dea4e ...
21:13:07.121 [pool-1-thread-2] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Unable to resolve location classpath:db/callback.
21:13:07.121 [pool-1-thread-2] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Scanning for classpath resources at 'classpath:db/migration' ...
21:13:07.121 [pool-1-thread-2] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Determining location urls for classpath:db/migration using ClassLoader jdk.internal.loader.ClassLoaders$AppClassLoader@70dea4e ...
21:13:07.122 [pool-1-thread-2] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Scanning URL: jar:file:/C:/Users/jland/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/scalameta/metals_2.13/1.2.2/metals_2.13-1.2.2.jar!/db/migration
21:13:07.124 [pool-1-thread-2] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/
21:13:07.124 [pool-1-thread-2] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/V1__Create_tables.sql
21:13:07.124 [pool-1-thread-2] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/V2__Server_discovery.sql
21:13:07.124 [pool-1-thread-2] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/V3__Jar_symbols.sql
21:13:07.124 [pool-1-thread-2] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/V4__Fingerprints.sql
21:13:07.124 [pool-1-thread-2] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Scanning for classes at classpath:db/migration
21:13:07.125 [pool-1-thread-2] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
21:13:07.125 [pool-1-thread-2] DEBUG org.flywaydb.core.internal.resource.ResourceNameValidator -- Validating V1__Create_tables.sql
21:13:07.126 [pool-1-thread-2] DEBUG org.flywaydb.core.internal.resource.ResourceNameValidator -- Validating V3__Jar_symbols.sql
21:13:07.126 [pool-1-thread-2] DEBUG org.flywaydb.core.internal.resource.ResourceNameValidator -- Validating V2__Server_discovery.sql
21:13:07.126 [pool-1-thread-2] DEBUG org.flywaydb.core.internal.resource.ResourceNameValidator -- Validating V4__Fingerprints.sql
21:13:07.185 [pool-1-thread-2] INFO org.flywaydb.core.FlywayExecutor -- Database: jdbc:h2:file:C:\Users\jland\Documents\CS474_Paper_Project\.metals\metals (H2 2.2)
21:13:07.185 [pool-1-thread-2] DEBUG org.flywaydb.core.FlywayExecutor -- Driver: H2 JDBC Driver 2.2.224 (2023-09-17)
21:13:07.185 [pool-1-thread-2] DEBUG org.flywaydb.core.FlywayExecutor -- DDL Transactions Supported: false
21:13:07.186 [pool-1-thread-2] DEBUG org.flywaydb.core.internal.schemahistory.SchemaHistoryFactory -- Schemas: 
21:13:07.186 [pool-1-thread-2] DEBUG org.flywaydb.core.internal.schemahistory.SchemaHistoryFactory -- Default schema: null
21:13:07.189 [pool-1-thread-2] WARN org.flywaydb.core.internal.database.base.Database -- Flyway upgrade recommended: H2 2.2.224 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
21:13:07.189 [pool-1-thread-2] DEBUG org.flywaydb.core.internal.callback.SqlScriptCallbackFactory -- Scanning for SQL callbacks ...
21:13:07.189 [pool-1-thread-2] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
21:13:07.194 [pool-1-thread-2] DEBUG org.flywaydb.core.internal.command.DbValidate -- Validating migrations ...
21:13:07.196 [pool-1-thread-2] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
21:13:07.200 [pool-1-thread-2] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V1__Create_tables.sql (filename: V1__Create_tables.sql)
21:13:07.200 [pool-1-thread-2] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
21:13:07.200 [pool-1-thread-2] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V3__Jar_symbols.sql (filename: V3__Jar_symbols.sql)
21:13:07.200 [pool-1-thread-2] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V2__Server_discovery.sql (filename: V2__Server_discovery.sql)
21:13:07.200 [pool-1-thread-2] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V4__Fingerprints.sql (filename: V4__Fingerprints.sql)
21:13:07.201 [pool-1-thread-2] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V1__Create_tables.sql (filename: V1__Create_tables.sql)
21:13:07.201 [pool-1-thread-2] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
21:13:07.201 [pool-1-thread-2] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V3__Jar_symbols.sql (filename: V3__Jar_symbols.sql)
21:13:07.201 [pool-1-thread-2] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V2__Server_discovery.sql (filename: V2__Server_discovery.sql)
21:13:07.201 [pool-1-thread-2] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V4__Fingerprints.sql (filename: V4__Fingerprints.sql)
21:13:07.207 [pool-1-thread-2] INFO org.flywaydb.core.internal.command.DbValidate -- Successfully validated 4 migrations (execution time 00:00.012s)
21:13:07.209 [pool-1-thread-2] DEBUG org.flywaydb.core.internal.command.DbSchemas -- Skipping creation of existing schema: "PUBLIC"
21:13:07.213 [pool-1-thread-2] INFO org.flywaydb.core.internal.command.DbMigrate -- Current version of schema "PUBLIC": 4
21:13:07.215 [pool-1-thread-2] INFO org.flywaydb.core.internal.command.DbMigrate -- Schema "PUBLIC" is up to date. No migration necessary.
21:13:07.419 [pool-1-thread-2] DEBUG org.flywaydb.core.FlywayExecutor -- Memory usage: 60 of 144M
2024.03.04 21:13:07 WARN  no build tool detected in workspace 'C:\Users\jland\Documents\CS474_Paper_Project'. The most common cause for this problem is that the editor was opened in the wrong working directory, for example if you use sbt then the workspace directory should contain build.sbt. 
2024.03.04 21:13:07 WARN  Build server is not auto-connectable.
2024.03.04 21:13:44 INFO  no build target found for C:\Users\jland\Documents\CS474_Paper_Project\part_2_code\build.sbt. Using presentation compiler with project's scala-library version: 3.3.1
2024.03.04 21:13:45 INFO  time: code lens generation in 3.6s
2024.03.04 21:13:55 ERROR Failed to tokenize input for semantic tokens for C:\Users\jland\Documents\CS474_Paper_Project\part_2_code\src\main\scala\Main.scala
scala.meta.tokenizers.TokenizeException: <input>:5: error: illegal character '\u00a0'
  def Problem_1(regex: String): Int = {
^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchOther$1(LegacyScanner.scala:469)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:474)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2024.03.04 21:13:58 ERROR Failed to tokenize input for semantic tokens for C:\Users\jland\Documents\CS474_Paper_Project\part_2_code\src\main\scala\Main.scala
scala.meta.tokenizers.TokenizeException: <input>:6: error: illegal character '\u00a0'
  def Problem_1(regex: String): Int = {
^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchOther$1(LegacyScanner.scala:469)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:474)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2024.03.04 21:13:59 ERROR Failed to tokenize input for semantic tokens for C:\Users\jland\Documents\CS474_Paper_Project\part_2_code\src\main\scala\Main.scala
scala.meta.tokenizers.TokenizeException: <input>:9: error: illegal character '\u00a0'
  def Problem_1(regex: String): Int = {
^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchOther$1(LegacyScanner.scala:469)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:474)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2024.03.04 21:14:00 ERROR Failed to tokenize input for semantic tokens for C:\Users\jland\Documents\CS474_Paper_Project\part_2_code\src\main\scala\Main.scala
scala.meta.tokenizers.TokenizeException: <input>:9: error: illegal character '\u00a0'
  def Problem_1(regex: String): Int = {
^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchOther$1(LegacyScanner.scala:469)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:474)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2024.03.04 21:14:01 ERROR Failed to tokenize input for semantic tokens for C:\Users\jland\Documents\CS474_Paper_Project\part_2_code\src\main\scala\Main.scala
scala.meta.tokenizers.TokenizeException: <input>:9: error: illegal character '\u00a0'
  def Problem_1(regex: String): Int = {
^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchOther$1(LegacyScanner.scala:469)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:474)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2024.03.04 21:14:01 ERROR Failed to tokenize input for semantic tokens for C:\Users\jland\Documents\CS474_Paper_Project\part_2_code\src\main\scala\Main.scala
scala.meta.tokenizers.TokenizeException: <input>:9: error: illegal character '\u00a0'
  def Problem_1(regex: String): Int = {
^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchOther$1(LegacyScanner.scala:469)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:474)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2024.03.04 21:14:03 ERROR Failed to tokenize input for semantic tokens for C:\Users\jland\Documents\CS474_Paper_Project\part_2_code\src\main\scala\Main.scala
scala.meta.tokenizers.TokenizeException: <input>:9: error: illegal character '\u00a0'
  def Problem_1(regex: String): Int = {
^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchOther$1(LegacyScanner.scala:469)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:474)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2024.03.04 21:14:03 ERROR Failed to tokenize input for semantic tokens for C:\Users\jland\Documents\CS474_Paper_Project\part_2_code\src\main\scala\Main.scala
scala.meta.tokenizers.TokenizeException: <input>:9: error: illegal character '\u00a0'
  def Problem_1(regex: String): Int = {
^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchOther$1(LegacyScanner.scala:469)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:474)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2024.03.04 21:14:03 ERROR Failed to tokenize input for semantic tokens for C:\Users\jland\Documents\CS474_Paper_Project\part_2_code\src\main\scala\Main.scala
scala.meta.tokenizers.TokenizeException: <input>:10: error: illegal character '\u00a0'
  def Problem_1(regex: String): Int = {
^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchOther$1(LegacyScanner.scala:469)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:474)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2024.03.04 21:14:05 ERROR Failed to tokenize input for semantic tokens for C:\Users\jland\Documents\CS474_Paper_Project\part_2_code\src\main\scala\Main.scala
scala.meta.tokenizers.TokenizeException: <input>:10: error: illegal character '\u00a0'
  def Problem_1(regex: String): Int = {
^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchOther$1(LegacyScanner.scala:469)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:474)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2024.03.04 21:14:05 WARN  Could not find semantic tokens for: file:///C:/Users/jland/Documents/CS474_Paper_Project/part_2_code/src/main/scala/Main.scala
2024.03.04 21:14:06 WARN  Could not find semantic tokens for: file:///C:/Users/jland/Documents/CS474_Paper_Project/part_2_code/src/main/scala/Main.scala
2024.03.04 21:14:07 ERROR Failed to tokenize input for semantic tokens for C:\Users\jland\Documents\CS474_Paper_Project\part_2_code\src\main\scala\Main.scala
scala.meta.tokenizers.TokenizeException: <input>:10: error: illegal character '\u00a0'
  def Problem_1(regex: String): Int = {
^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchOther$1(LegacyScanner.scala:469)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:474)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2024.03.04 21:14:08 WARN  Could not find semantic tokens for: file:///C:/Users/jland/Documents/CS474_Paper_Project/part_2_code/src/main/scala/Main.scala
2024.03.04 21:14:08 ERROR Failed to tokenize input for semantic tokens for C:\Users\jland\Documents\CS474_Paper_Project\part_2_code\src\main\scala\Main.scala
scala.meta.tokenizers.TokenizeException: <input>:10: error: illegal character '\u00a0'
  def Problem_1(regex: String): Int = {
^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchOther$1(LegacyScanner.scala:469)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:474)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2024.03.04 21:14:09 ERROR Failed to tokenize input for semantic tokens for C:\Users\jland\Documents\CS474_Paper_Project\part_2_code\src\main\scala\Main.scala
scala.meta.tokenizers.TokenizeException: <input>:10: error: illegal character '\u00a0'
  def Problem_1(regex: String): Int = {
^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchOther$1(LegacyScanner.scala:469)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:474)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2024.03.04 21:14:09 ERROR Failed to tokenize input for semantic tokens for C:\Users\jland\Documents\CS474_Paper_Project\part_2_code\src\main\scala\Main.scala
scala.meta.tokenizers.TokenizeException: <input>:10: error: illegal character '\u00a0'
  def Problem_1(regex: String): Int = {
^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchOther$1(LegacyScanner.scala:469)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:474)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2024.03.04 21:14:10 ERROR Failed to tokenize input for semantic tokens for C:\Users\jland\Documents\CS474_Paper_Project\part_2_code\src\main\scala\Main.scala
scala.meta.tokenizers.TokenizeException: <input>:10: error: illegal character '\u00a0'
  def Problem_1(regex: String): Int = {
^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchOther$1(LegacyScanner.scala:469)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:474)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2024.03.04 21:14:11 ERROR Failed to tokenize input for semantic tokens for C:\Users\jland\Documents\CS474_Paper_Project\part_2_code\src\main\scala\Main.scala
scala.meta.tokenizers.TokenizeException: <input>:10: error: illegal character '\u00a0'
  def Problem_1(regex: String): Int = {
^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchOther$1(LegacyScanner.scala:469)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:474)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2024.03.04 21:14:14 ERROR Failed to tokenize input for semantic tokens for C:\Users\jland\Documents\CS474_Paper_Project\part_2_code\src\main\scala\Main.scala
scala.meta.tokenizers.TokenizeException: <input>:10: error: illegal character '\u00a0'
  def Problem_1(regex: String): Int = {
^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchOther$1(LegacyScanner.scala:469)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:474)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2024.03.04 21:14:22 ERROR Failed to tokenize input for semantic tokens for C:\Users\jland\Documents\CS474_Paper_Project\part_2_code\build.sbt
scala.meta.tokenizers.TokenizeException: <input>:7: error: illegal character '\u00a0'
  .in(file("."))
^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchOther$1(LegacyScanner.scala:469)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:474)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2024.03.04 21:14:26 ERROR Failed to tokenize input for semantic tokens for C:\Users\jland\Documents\CS474_Paper_Project\part_2_code\src\main\scala\Main.scala
scala.meta.tokenizers.TokenizeException: <input>:10: error: illegal character '\u00a0'
  def Problem_1(regex: String): Int = {
^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchOther$1(LegacyScanner.scala:469)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:474)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2024.03.04 21:14:29 ERROR Failed to tokenize input for semantic tokens for C:\Users\jland\Documents\CS474_Paper_Project\part_2_code\src\main\scala\Main.scala
scala.meta.tokenizers.TokenizeException: <input>:10: error: illegal character '\u00a0'
  def Problem_1(regex: String): Int = {
^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchOther$1(LegacyScanner.scala:469)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:474)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2024.03.04 21:14:30 ERROR Failed to tokenize input for semantic tokens for C:\Users\jland\Documents\CS474_Paper_Project\part_2_code\src\main\scala\Main.scala
scala.meta.tokenizers.TokenizeException: <input>:10: error: illegal character '\u00a0'
  def Problem_1(regex: String): Int = {
^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchOther$1(LegacyScanner.scala:469)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:474)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2024.03.04 21:14:33 ERROR Failed to tokenize input for semantic tokens for C:\Users\jland\Documents\CS474_Paper_Project\part_2_code\src\main\scala\Main.scala
scala.meta.tokenizers.TokenizeException: <input>:9: error: illegal character '\u00a0'
  def Problem_1(regex: String): Int = {
^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchOther$1(LegacyScanner.scala:469)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:474)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2024.03.04 21:14:35 ERROR Failed to tokenize input for semantic tokens for C:\Users\jland\Documents\CS474_Paper_Project\part_2_code\src\main\scala\Main.scala
scala.meta.tokenizers.TokenizeException: <input>:13: error: illegal character '\u00a0'
  val tryAutomotan = regGuy.toAutomaton()
^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchOther$1(LegacyScanner.scala:469)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:474)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2024.03.04 21:14:35 ERROR Failed to tokenize input for semantic tokens for C:\Users\jland\Documents\CS474_Paper_Project\part_2_code\src\main\scala\Main.scala
scala.meta.tokenizers.TokenizeException: <input>:12: error: illegal character '\u00a0'
  val tryAutomotan = regGuy.toAutomaton()
^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchOther$1(LegacyScanner.scala:469)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:474)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2024.03.04 21:14:36 ERROR Failed to tokenize input for semantic tokens for C:\Users\jland\Documents\CS474_Paper_Project\part_2_code\src\main\scala\Main.scala
scala.meta.tokenizers.TokenizeException: <input>:10: error: illegal character '\u00a0'
  val tryAutomotan = regGuy.toAutomaton()
^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchOther$1(LegacyScanner.scala:469)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:474)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2024.03.04 21:14:37 ERROR Failed to tokenize input for semantic tokens for C:\Users\jland\Documents\CS474_Paper_Project\part_2_code\src\main\scala\Main.scala
scala.meta.tokenizers.TokenizeException: <input>:11: error: illegal character '\u00a0'
  val tryAutomotan = regGuy.toAutomaton()
^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchOther$1(LegacyScanner.scala:469)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:474)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2024.03.04 21:14:39 ERROR Failed to tokenize input for semantic tokens for C:\Users\jland\Documents\CS474_Paper_Project\part_2_code\src\main\scala\Main.scala
scala.meta.tokenizers.TokenizeException: <input>:11: error: illegal character '\u00a0'
  val tryAutomotan = regGuy.toAutomaton()
^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchOther$1(LegacyScanner.scala:469)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:474)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2024.03.04 21:14:41 ERROR Failed to tokenize input for semantic tokens for C:\Users\jland\Documents\CS474_Paper_Project\part_2_code\src\main\scala\Main.scala
scala.meta.tokenizers.TokenizeException: <input>:12: error: illegal character '\u00a0'
  val stringOut = tryAutomotan.getNumberOfStates()
^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchOther$1(LegacyScanner.scala:469)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:474)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2024.03.04 21:14:42 ERROR Failed to tokenize input for semantic tokens for C:\Users\jland\Documents\CS474_Paper_Project\part_2_code\src\main\scala\Main.scala
scala.meta.tokenizers.TokenizeException: <input>:11: error: illegal character '\u00a0'
  val stringOut = tryAutomotan.getNumberOfStates()
^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchOther$1(LegacyScanner.scala:469)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:474)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2024.03.04 21:14:42 ERROR Failed to tokenize input for semantic tokens for C:\Users\jland\Documents\CS474_Paper_Project\part_2_code\src\main\scala\Main.scala
scala.meta.tokenizers.TokenizeException: <input>:12: error: illegal character '\u00a0'
  val stringOut = tryAutomotan.getNumberOfStates()
^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchOther$1(LegacyScanner.scala:469)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:474)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2024.03.04 21:14:44 ERROR Failed to tokenize input for semantic tokens for C:\Users\jland\Documents\CS474_Paper_Project\part_2_code\src\main\scala\Main.scala
scala.meta.tokenizers.TokenizeException: <input>:12: error: illegal character '\u00a0'
  val stringOut = tryAutomotan.getNumberOfStates()
^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchOther$1(LegacyScanner.scala:469)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:474)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2024.03.04 21:14:45 ERROR Failed to tokenize input for semantic tokens for C:\Users\jland\Documents\CS474_Paper_Project\part_2_code\src\main\scala\Main.scala
scala.meta.tokenizers.TokenizeException: <input>:12: error: illegal character '\u00a0'
  val stringOut = tryAutomotan.getNumberOfStates()
^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchOther$1(LegacyScanner.scala:469)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:474)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2024.03.04 21:14:48 ERROR Failed to tokenize input for semantic tokens for C:\Users\jland\Documents\CS474_Paper_Project\part_2_code\src\main\scala\Main.scala
scala.meta.tokenizers.TokenizeException: <input>:13: error: illegal character '\u00a0'
  return stringOut
^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchOther$1(LegacyScanner.scala:469)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:474)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2024.03.04 21:14:51 ERROR Failed to tokenize input for semantic tokens for C:\Users\jland\Documents\CS474_Paper_Project\part_2_code\src\main\scala\Main.scala
scala.meta.tokenizers.TokenizeException: <input>:12: error: illegal character '\u00a0'
  }
^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchOther$1(LegacyScanner.scala:469)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:474)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2024.03.04 21:14:53 ERROR Failed to tokenize input for semantic tokens for C:\Users\jland\Documents\CS474_Paper_Project\part_2_code\src\main\scala\Main.scala
scala.meta.tokenizers.TokenizeException: <input>:14: error: illegal character '\u00a0'
  println(Problem_1)
^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchOther$1(LegacyScanner.scala:469)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:474)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2024.03.04 21:14:54 WARN  no build target for: C:\Users\jland\Documents\CS474_Paper_Project\part_2_code\src\main\scala\Main.scala
2024.03.04 21:14:54 ERROR Failed to tokenize input for semantic tokens for C:\Users\jland\Documents\CS474_Paper_Project\part_2_code\src\main\scala\Main.scala
scala.meta.tokenizers.TokenizeException: <input>:14: error: illegal character '\u00a0'
  println(Problem_1)
^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchOther$1(LegacyScanner.scala:469)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:474)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2024.03.04 21:14:55 WARN  no build target for: C:\Users\jland\Documents\CS474_Paper_Project\part_2_code\src\main\scala\Main.scala
2024.03.04 21:14:55 ERROR Failed to tokenize input for semantic tokens for C:\Users\jland\Documents\CS474_Paper_Project\part_2_code\src\main\scala\Main.scala
scala.meta.tokenizers.TokenizeException: <input>:14: error: illegal character '\u00a0'
  println(Problem_1)
^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchOther$1(LegacyScanner.scala:469)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:474)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2024.03.04 21:15:13 ERROR Failed to tokenize input for semantic tokens for C:\Users\jland\Documents\CS474_Paper_Project\part_2_code\build.sbt
scala.meta.tokenizers.TokenizeException: <input>:7: error: illegal character '\u00a0'
  .in(file("."))
^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchOther$1(LegacyScanner.scala:469)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:474)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

